{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Giới thiệu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bài toán này được xây dựng để dự doán giá xe oto dựa trên các dữ liệu tự thu thập được từ  trang web. \n",
    "- Bộ dữ liệu được thu thập từ trang web https://bonbanh.com/ là nơi mua bán cái loại xe oto cũ và mới.  \n",
    "- Chúng ta sử dụng thư viện BeautifulSoup để truy cập, lấy dữ liệu từ trang web. Dùng 2 mô hình RandomForestRegressor và LinearRegression để xây dựng mô hình dự đoán giá xe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crawl dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "from csv import writer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hàm gộp các phần tử trong mảng thành nhiều mảng con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_split(listA, n):\n",
    "    for x in range(0, len(listA), n):\n",
    "        every_chunk = listA[x: n+x]\n",
    "        if len(every_chunk) < n:\n",
    "            every_chunk = every_chunk + \\\n",
    "                [None for y in range(n-len(every_chunk))]\n",
    "        yield every_chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hàm crawl chi tiết xe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Detail(detail,s):\n",
    "    if detail == \"cb2_02\":\n",
    "        link=i.find(\"a\").get('href') # Tìm thẻ a và lấy các chuỗi trong thuộc tính href\n",
    "        link_1 = \"https://bonbanh.com/\"+link\n",
    "        # print(link_1)\n",
    "        page_1 = urllib.request.urlopen(link_1)\n",
    "        soup_1 = BeautifulSoup(page_1, 'html.parser')\n",
    "        # Basic Infomation\n",
    "        BasicInfo= soup_1.findAll(\"div\",class_='col')[0]\n",
    "        madeIn=BasicInfo.findAll(\"span\",class_='inp')[0].text\n",
    "        s.append(madeIn)\n",
    "        carType=BasicInfo.findAll(\"span\",class_='inp')[2].text\n",
    "        s.append(carType)\n",
    "        Km=BasicInfo.findAll(\"span\",class_='inp')[3].text\n",
    "        s.append(Km)\n",
    "        carColor=BasicInfo.findAll(\"span\",class_='inp')[4].text\n",
    "        s.append(carColor)\n",
    "        Interior_Color = BasicInfo.findAll(\"span\",class_='inp')[5].text\n",
    "        s.append(Interior_Color)\n",
    "        carDoor = BasicInfo.findAll(\"span\",class_='inp')[6].text\n",
    "        s.append(carDoor)\n",
    "        carSeat=BasicInfo.findAll(\"span\",class_='inp')[7].text\n",
    "        s.append(carSeat)\n",
    "        # Engine\n",
    "        BasicInfo= soup_1.findAll(\"div\",class_='col')[1]\n",
    "        carEngine = BasicInfo.findAll(\"span\",class_='inp')[0].text\n",
    "        s.append(carEngine)\n",
    "        Gearbox = BasicInfo.findAll(\"span\",class_='inp')[2].text\n",
    "        s.append(Gearbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tiến hành crawl dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1980\n"
     ]
    }
   ],
   "source": [
    "s = []\n",
    "cb = ['cb5','cb1','cb2_02','cb3','cb4','cb7']\n",
    "data_in = []\n",
    "data_out = []\n",
    "b = []\n",
    "for k in range(1,100):\n",
    "    access_homepage = \"https://bonbanh.com/oto/page,\"+str(k)\n",
    "    page = urllib.request.urlopen(access_homepage)\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    for i in soup.findAll('li', class_='car-item row1'):\n",
    "        for j in range(len(cb)):\n",
    "            k = i.find(\"div\",class_= cb[j])\n",
    "            x = k.get_text()\n",
    "            s.append(x)\n",
    "            get_Detail(cb[j],s)\n",
    "    for i in soup.findAll('li', class_='car-item row2'):\n",
    "        for j in range(len(cb)):\n",
    "            k = i.find(\"div\",class_= cb[j])\n",
    "            x = k.get_text()\n",
    "            s.append(x)\n",
    "            get_Detail(cb[j],s)\n",
    "    # s\n",
    "data_out = list(list_split(s,15))\n",
    "print(len(data_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lưu dữ liệu vào file csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "data = [\"ID\",\"Category\",\"Name\",\"Assemble\",\"Type\",\"Km\",\"CarColor\",\"InteriorColor\",\"CarDoor\",\"CarSeat\",\"Engine\",\"Gearbox\",\"Price\",\"Location\",\"Contact\"]\n",
    "with open('raw_data.csv', 'a',newline='') as f: \n",
    "    write = csv.writer(f) \n",
    "    write.writerow(data) \n",
    "    f.close()\n",
    "for l in range(0,len(data_out)):\n",
    "    with open('raw_data.csv', 'a',encoding= \"utf8\",newline='') as f_object:  \n",
    "        # Pass the CSV  file object to the writer() function\n",
    "        writer_object = writer(f_object)\n",
    "        # Result - a writer object\n",
    "        # Pass the data in the list as an argument into the writerow() function\n",
    "        writer_object.writerow(data_out[l])  \n",
    "        # Close the file object\n",
    "        f_object.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a42ccb73e7d9bfdf27e036f1d2b8b681e55fc0743cc5586bc2474d4a60f4b886"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
